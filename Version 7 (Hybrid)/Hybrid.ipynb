{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras import metrics\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utilities.model_visualization import model_to_png\n",
    "\n",
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os # used for navigating to image path\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "import cv2\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pickle\n",
    "from scipy import misc\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          HARVEY AFTER DONNA KISSED HIM: https://t.co/mz...\n",
      "text_info                                       not_informative\n",
      "image_path    data_image/hurricane_harvey/14_9_2017/90825435...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_pickle('dataset.pkl')\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pos = int(df['text'].count()*0.8)\n",
    "train = df[:split_pos]\n",
    "test = df[split_pos:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumn = 'text'\n",
    "labelColumn = 'text_info'\n",
    "\n",
    "tags = train[labelColumn]\n",
    "texts = train[dataColumn]\n",
    "\n",
    "tags_Y = test[labelColumn]\n",
    "texts_Y = test[dataColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags.astype(str))\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "\n",
    "# For testing data\n",
    "le_Y = LabelEncoder()\n",
    "tags_Y = le_Y.fit_transform(tags_Y.astype(str))\n",
    "tok_Y = Tokenizer(num_words=num_max)\n",
    "tok_Y.fit_on_texts(texts_Y)\n",
    "mat_texts_Y = tok.texts_to_matrix(texts_Y,mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "\n",
    "# For testing data\n",
    "cnn_texts_seq_Y = tok.texts_to_sequences(texts_Y)\n",
    "cnn_texts_mat_Y = sequence.pad_sequences(cnn_texts_seq_Y,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"text_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=4, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    # load the whole embedding into memory\n",
    "    embeddings_index = dict()\n",
    "    f = open('Embeddings/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = np.zeros((len(tok.word_index) + 1, 100))\n",
    "    for word, i in tok.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    #text classifier\n",
    "    inputs = Input(shape=(100,))\n",
    "    e = Embedding(len(tok.word_index) + 1,\n",
    "                  100, \n",
    "                  weights=[embedding_matrix],\n",
    "                  input_length=max_len, \n",
    "                  trainable=False)(inputs)\n",
    "    x = Dropout(0.2)(e)\n",
    "    x = Conv1D(128,\n",
    "               3,\n",
    "               padding='valid',\n",
    "               activation='relu',\n",
    "               strides=1)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    hybrid_link = Dense(32, activation='relu', name='hybrid_link')(x)\n",
    "    x = Dense(1, activation='sigmoid', name='Text_Classifier')(hybrid_link)\n",
    "    text_classifier = x\n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(4, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    #hybrid model\n",
    "    concatenate_layer = concatenate([image_model, hybrid_link]) \n",
    "    hybrid = Dense(4, activation='softmax', name='Hybrid_Classifier')(concatenate_layer)\n",
    "    model = Model(inputs=[vgg.input, inputs], outputs=[hybrid,text_classifier])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(4, activation = 'softmax',name='Hybrid_Classifier')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    model = Model(inputs=[vgg.input], outputs=[image_model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "hybrid_model = get_hybrid_model()\n",
    "vgg_model = get_vgg_model()\n",
    "hybrid_model.compile(loss=['categorical_crossentropy','binary_crossentropy'],\n",
    "                       optimizer= optimizers.adam(lr=0.0001),\n",
    "                       metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])\n",
    "vgg_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer= optimizers.adam(lr=0.0001),\n",
    "                       metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])\n",
    "# hybrid_model.summary()\n",
    "plot_model(hybrid_model, to_file='hybrid.png')\n",
    "plot_model(vgg_model, to_file='vgg.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE =224\n",
    "dataset_dir = 'H:/FYP DATASETS/FYP DATASETS/Crisis/'\n",
    "\n",
    "def load_img(img):\n",
    "    path = os.path.join(dataset_dir, img)\n",
    "    rows=224\n",
    "    columns=224\n",
    "    img= cv2.resize(cv2.imread(path,cv2.IMREAD_COLOR),(rows,columns),interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    train.at[index,'image_path'] = load_img(row['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(damage):\n",
    "    # integer encode\n",
    "    damage = np.array(damage)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(damage)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          HARVEY AFTER DONNA KISSED HIM: https://t.co/mz...\n",
      "text_info                                       not_informative\n",
      "image_path    [[[141, 150, 137], [141, 150, 137], [141, 150,...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = encode_label(train.iloc[:]['damage'])\n",
    "print(train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['irrelevant' 'severe_damage' 'mild_damage' 'little_or_no_damage']\n"
     ]
    }
   ],
   "source": [
    "print(train.damage.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train['image_path'].tolist()\n",
    "# no need to convert y to list as it is 1 dim encoding takes care of it\n",
    "train_images = np.array(train_images)\n",
    "train_text = np.array(train['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"hybrid_checkpoints_1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_Hybrid_Classifier_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_Hybrid_Classifier_acc', min_delta=0, patience=3, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "load_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10807 samples, validate on 3603 samples\n",
      "Epoch 1/40\n",
      "10807/10807 [==============================] - 518s 48ms/step - loss: 1.2721 - Hybrid_Classifier_loss: 0.7152 - Text_Classifier_loss: 0.5570 - Hybrid_Classifier_acc: 0.8015 - Hybrid_Classifier_mean_absolute_error: 0.1773 - Hybrid_Classifier_categorical_accuracy: 0.8015 - Text_Classifier_acc: 0.7250 - Text_Classifier_mean_absolute_error: 0.3726 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.1427 - val_Hybrid_Classifier_loss: 0.6660 - val_Text_Classifier_loss: 0.4768 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1853 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.7932 - val_Text_Classifier_mean_absolute_error: 0.3359 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00001: val_Hybrid_Classifier_acc improved from -inf to 0.79961, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 2/40\n",
      "10807/10807 [==============================] - 270s 25ms/step - loss: 1.1479 - Hybrid_Classifier_loss: 0.6657 - Text_Classifier_loss: 0.4822 - Hybrid_Classifier_acc: 0.8058 - Hybrid_Classifier_mean_absolute_error: 0.1667 - Hybrid_Classifier_categorical_accuracy: 0.8058 - Text_Classifier_acc: 0.7788 - Text_Classifier_mean_absolute_error: 0.3191 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0981 - val_Hybrid_Classifier_loss: 0.6495 - val_Text_Classifier_loss: 0.4486 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1766 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.8038 - val_Text_Classifier_mean_absolute_error: 0.2919 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00002: val_Hybrid_Classifier_acc did not improve from 0.79961\n",
      "Epoch 3/40\n",
      "10807/10807 [==============================] - 239s 22ms/step - loss: 1.1104 - Hybrid_Classifier_loss: 0.6533 - Text_Classifier_loss: 0.4572 - Hybrid_Classifier_acc: 0.8062 - Hybrid_Classifier_mean_absolute_error: 0.1645 - Hybrid_Classifier_categorical_accuracy: 0.8062 - Text_Classifier_acc: 0.7951 - Text_Classifier_mean_absolute_error: 0.2982 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0825 - val_Hybrid_Classifier_loss: 0.6362 - val_Text_Classifier_loss: 0.4463 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1716 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.8010 - val_Text_Classifier_mean_absolute_error: 0.3030 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: val_Hybrid_Classifier_acc did not improve from 0.79961\n",
      "Epoch 4/40\n",
      "10807/10807 [==============================] - 240s 22ms/step - loss: 1.0818 - Hybrid_Classifier_loss: 0.6391 - Text_Classifier_loss: 0.4427 - Hybrid_Classifier_acc: 0.8056 - Hybrid_Classifier_mean_absolute_error: 0.1614 - Hybrid_Classifier_categorical_accuracy: 0.8056 - Text_Classifier_acc: 0.7998 - Text_Classifier_mean_absolute_error: 0.2877 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0699 - val_Hybrid_Classifier_loss: 0.6308 - val_Text_Classifier_loss: 0.4392 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1664 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.8029 - val_Text_Classifier_mean_absolute_error: 0.2878 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_Hybrid_Classifier_acc did not improve from 0.79961\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hybrid_model.save_weights('initial_hybrid.h5')\n",
    "hybrid_history = hybrid_model.fit(x=[train_images,cnn_texts_mat], y=[y,tags],\n",
    "                           epochs=40,\n",
    "                           batch_size=20,\n",
    "                           validation_split=0.25,\n",
    "                           shuffle=True,\n",
    "                           callbacks = callbacks_list,\n",
    "                           verbose=1)\n",
    "hybrid_time = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# vgg_history = vgg_model.fit(x=[train_images], y=[y],\n",
    "#                            epochs=40,\n",
    "#                            batch_size=10,\n",
    "#                            validation_split=0.2,\n",
    "#                            shuffle=True,\n",
    "#                            verbose=1)\n",
    "# vgg_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid train time 1360.0757529735565\n",
      "load time 693.1423366069794\n"
     ]
    }
   ],
   "source": [
    "print('Hybrid train time ' + str(hybrid_time))\n",
    "print('load time ' + str(load_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.save_weights('hybrid.h5')\n",
    "#vgg_model.save_weights('vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
