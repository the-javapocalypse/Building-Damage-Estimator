{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras import metrics\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utilities.model_visualization import model_to_png\n",
    "\n",
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os # used for navigating to image path\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "import cv2\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pickle\n",
    "from scipy import misc\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          Harvey, Irma, and Maria: Hurricane Recovery Co...\n",
      "text_info                                           informative\n",
      "image_path    data_image/hurricane_maria/22_10_2017/92206396...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_pickle('dataset.pkl')\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['irrelevant' 'severe_damage' 'mild_damage' 'little_or_no_damage']\n"
     ]
    }
   ],
   "source": [
    "print(df['damage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pos = int(df['text'].count()*0.8)\n",
    "train = df[:split_pos]\n",
    "test = df[split_pos:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumn = 'text'\n",
    "labelColumn = 'text_info'\n",
    "\n",
    "tags = train[labelColumn]\n",
    "texts = train[dataColumn]\n",
    "\n",
    "tags_Y = test[labelColumn]\n",
    "texts_Y = test[dataColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags.astype(str))\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "\n",
    "# For testing data\n",
    "le_Y = LabelEncoder()\n",
    "tags_Y = le_Y.fit_transform(tags_Y.astype(str))\n",
    "tok_Y = Tokenizer(num_words=num_max)\n",
    "tok_Y.fit_on_texts(texts_Y)\n",
    "mat_texts_Y = tok.texts_to_matrix(texts_Y,mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "\n",
    "# For testing data\n",
    "cnn_texts_seq_Y = tok.texts_to_sequences(texts_Y)\n",
    "cnn_texts_mat_Y = sequence.pad_sequences(cnn_texts_seq_Y,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"text_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=4, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    # load the whole embedding into memory\n",
    "    embeddings_index = dict()\n",
    "    f = open('Embeddings/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = np.zeros((len(tok.word_index) + 1, 100))\n",
    "    for word, i in tok.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    #text classifier\n",
    "    inputs = Input(shape=(100,))\n",
    "    e = Embedding(len(tok.word_index) + 1,\n",
    "                  100, \n",
    "                  weights=[embedding_matrix],\n",
    "                  input_length=max_len, \n",
    "                  trainable=False)(inputs)\n",
    "    x = Dropout(0.2)(e)\n",
    "    x = Conv1D(128,\n",
    "               3,\n",
    "               padding='valid',\n",
    "               activation='relu',\n",
    "               strides=1)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    hybrid_link = Dense(32, activation='relu', name='hybrid_link')(x)\n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(64, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    #hybrid model\n",
    "    concatenate_layer = concatenate([image_model, hybrid_link]) \n",
    "    hybrid = Dense(4, activation='softmax', name='Hybrid_Classifier')(concatenate_layer)\n",
    "    model = Model(inputs=[vgg.input, inputs], outputs=[hybrid])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(4, activation = 'softmax',name='Hybrid_Classifier')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    model = Model(inputs=[vgg.input], outputs=[image_model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "hybrid_model = get_hybrid_model()\n",
    "vgg_model = get_vgg_model()\n",
    "\n",
    "hybrid_model.compile(loss=['categorical_crossentropy'],\n",
    "                          optimizer= optimizers.Nadam(lr=0.00075,\n",
    "                               beta_1=0.5,\n",
    "                               beta_2=0.999,\n",
    "                               epsilon=None, \n",
    "                               schedule_decay=0.0001),\n",
    "                           metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])\n",
    "# .8039\n",
    "# hybrid_model.compile(loss=['categorical_crossentropy','binary_crossentropy'],\n",
    "#                        optimizer= optimizers.Nadam(lr=0.0006,\n",
    "#                                                    beta_1=0.9,\n",
    "#                                                    beta_2=0.999,\n",
    "#                                                    epsilon=None, \n",
    "#                                                    schedule_decay=0.0004),\n",
    "#                        metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])\n",
    "plot_model(hybrid_model, to_file='hybrid.png')\n",
    "plot_model(vgg_model, to_file='vgg.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE =224\n",
    "dataset_dir = 'H:/FYP DATASETS/FYP DATASETS/Crisis/'\n",
    "\n",
    "def load_img(img):\n",
    "    path = os.path.join(dataset_dir, img)\n",
    "    rows=224\n",
    "    columns=224\n",
    "    img= cv2.resize(cv2.imread(path,cv2.IMREAD_COLOR),(rows,columns),interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    train.at[index,'image_path'] = load_img(row['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(damage):\n",
    "    # integer encode\n",
    "    damage = np.array(damage)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(damage)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          Harvey, Irma, and Maria: Hurricane Recovery Co...\n",
      "text_info                                           informative\n",
      "image_path    [[[255, 255, 253], [255, 255, 253], [255, 255,...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = encode_label(train.iloc[:]['damage'])\n",
    "print(train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['irrelevant' 'severe_damage' 'mild_damage' 'little_or_no_damage']\n"
     ]
    }
   ],
   "source": [
    "print(train.damage.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train['image_path'].tolist()\n",
    "# no need to convert y to list as it is 1 dim encoding takes care of it\n",
    "train_images = np.array(train_images)\n",
    "train_text = np.array(train['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"hybrid_checkpoints_1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "load_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10807 samples, validate on 3603 samples\n",
      "Epoch 1/60\n",
      "10807/10807 [==============================] - 459s 43ms/step - loss: 0.6677 - acc: 0.8036 - mean_absolute_error: 0.1659 - categorical_accuracy: 0.8036 - val_loss: 0.6354 - val_acc: 0.8002 - val_mean_absolute_error: 0.1744 - val_categorical_accuracy: 0.8002\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80017, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 2/60\n",
      "10807/10807 [==============================] - 421s 39ms/step - loss: 0.6181 - acc: 0.8031 - mean_absolute_error: 0.1568 - categorical_accuracy: 0.8031 - val_loss: 0.6173 - val_acc: 0.8002 - val_mean_absolute_error: 0.1393 - val_categorical_accuracy: 0.8002\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80017\n",
      "Epoch 3/60\n",
      "10807/10807 [==============================] - 362s 33ms/step - loss: 0.5951 - acc: 0.8040 - mean_absolute_error: 0.1522 - categorical_accuracy: 0.8040 - val_loss: 0.6089 - val_acc: 0.8002 - val_mean_absolute_error: 0.1583 - val_categorical_accuracy: 0.8002\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80017\n",
      "Epoch 4/60\n",
      "10807/10807 [==============================] - 376s 35ms/step - loss: 0.5789 - acc: 0.8053 - mean_absolute_error: 0.1486 - categorical_accuracy: 0.8053 - val_loss: 0.6033 - val_acc: 0.8038 - val_mean_absolute_error: 0.1452 - val_categorical_accuracy: 0.8038\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80017 to 0.80377, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 5/60\n",
      "10807/10807 [==============================] - 376s 35ms/step - loss: 0.5654 - acc: 0.8049 - mean_absolute_error: 0.1461 - categorical_accuracy: 0.8049 - val_loss: 0.6228 - val_acc: 0.7996 - val_mean_absolute_error: 0.1788 - val_categorical_accuracy: 0.7996\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80377\n",
      "Epoch 6/60\n",
      "10807/10807 [==============================] - 376s 35ms/step - loss: 0.5484 - acc: 0.8090 - mean_absolute_error: 0.1422 - categorical_accuracy: 0.8090 - val_loss: 0.6022 - val_acc: 0.8029 - val_mean_absolute_error: 0.1624 - val_categorical_accuracy: 0.8029\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80377\n",
      "Epoch 7/60\n",
      "10807/10807 [==============================] - 375s 35ms/step - loss: 0.5335 - acc: 0.8103 - mean_absolute_error: 0.1387 - categorical_accuracy: 0.8103 - val_loss: 0.6303 - val_acc: 0.8024 - val_mean_absolute_error: 0.1317 - val_categorical_accuracy: 0.8024\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80377\n",
      "Epoch 8/60\n",
      "10807/10807 [==============================] - 375s 35ms/step - loss: 0.5180 - acc: 0.8118 - mean_absolute_error: 0.1361 - categorical_accuracy: 0.8118 - val_loss: 0.6069 - val_acc: 0.8043 - val_mean_absolute_error: 0.1529 - val_categorical_accuracy: 0.8043\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.80377 to 0.80433, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 9/60\n",
      "10807/10807 [==============================] - 368s 34ms/step - loss: 0.5052 - acc: 0.8141 - mean_absolute_error: 0.1327 - categorical_accuracy: 0.8141 - val_loss: 0.6139 - val_acc: 0.8027 - val_mean_absolute_error: 0.1536 - val_categorical_accuracy: 0.8027\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80433\n",
      "Epoch 10/60\n",
      "10807/10807 [==============================] - 375s 35ms/step - loss: 0.4909 - acc: 0.8178 - mean_absolute_error: 0.1296 - categorical_accuracy: 0.8178 - val_loss: 0.6254 - val_acc: 0.7963 - val_mean_absolute_error: 0.1534 - val_categorical_accuracy: 0.7963\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80433\n",
      "Epoch 11/60\n",
      "10807/10807 [==============================] - 370s 34ms/step - loss: 0.4742 - acc: 0.8240 - mean_absolute_error: 0.1260 - categorical_accuracy: 0.8240 - val_loss: 0.6328 - val_acc: 0.7968 - val_mean_absolute_error: 0.1470 - val_categorical_accuracy: 0.7968\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80433\n",
      "Epoch 12/60\n",
      "10807/10807 [==============================] - 377s 35ms/step - loss: 0.4598 - acc: 0.8271 - mean_absolute_error: 0.1228 - categorical_accuracy: 0.8271 - val_loss: 0.6547 - val_acc: 0.8013 - val_mean_absolute_error: 0.1345 - val_categorical_accuracy: 0.8013\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.80433\n",
      "Epoch 13/60\n",
      "10807/10807 [==============================] - 377s 35ms/step - loss: 0.4456 - acc: 0.8314 - mean_absolute_error: 0.1200 - categorical_accuracy: 0.8314 - val_loss: 0.6948 - val_acc: 0.7691 - val_mean_absolute_error: 0.1553 - val_categorical_accuracy: 0.7691\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80433\n",
      "Epoch 14/60\n",
      "10807/10807 [==============================] - 377s 35ms/step - loss: 0.4392 - acc: 0.8294 - mean_absolute_error: 0.1181 - categorical_accuracy: 0.8294 - val_loss: 0.6703 - val_acc: 0.7818 - val_mean_absolute_error: 0.1495 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80433\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hybrid_model.save_weights('initial_hybrid.h5')\n",
    "hybrid_history = hybrid_model.fit(x=[train_images,cnn_texts_mat], y=[y],\n",
    "                           epochs=60,\n",
    "                           batch_size=10,\n",
    "                           validation_split=0.25,\n",
    "                           shuffle=True,\n",
    "                           callbacks = callbacks_list,\n",
    "                           verbose=1)\n",
    "hybrid_time = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# vgg_history = vgg_model.fit(x=[train_images], y=[y],\n",
    "#                            epochs=40,\n",
    "#                            batch_size=10,\n",
    "#                            validation_split=0.2,\n",
    "#                            shuffle=True,\n",
    "#                            verbose=1)\n",
    "# vgg_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid train time 5487.857943534851\n",
      "load time 714.5321588516235\n"
     ]
    }
   ],
   "source": [
    "print('Hybrid train time ' + str(hybrid_time))\n",
    "print('load time ' + str(load_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.save_weights('hybrid.h5')\n",
    "#vgg_model.save_weights('vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
