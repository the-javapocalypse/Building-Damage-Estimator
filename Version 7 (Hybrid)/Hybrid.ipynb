{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras import metrics\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utilities.model_visualization import model_to_png\n",
    "\n",
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os # used for navigating to image path\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "import cv2\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pickle\n",
    "from scipy import misc\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          HARVEY AFTER DONNA KISSED HIM: https://t.co/mz...\n",
      "text_info                                       not_informative\n",
      "image_path    data_image/hurricane_harvey/14_9_2017/90825435...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_pickle('dataset.pkl')\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pos = int(df['text'].count()*0.8)\n",
    "train = df[:split_pos]\n",
    "test = df[split_pos:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumn = 'text'\n",
    "labelColumn = 'text_info'\n",
    "\n",
    "tags = train[labelColumn]\n",
    "texts = train[dataColumn]\n",
    "\n",
    "tags_Y = test[labelColumn]\n",
    "texts_Y = test[dataColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags.astype(str))\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "\n",
    "# For testing data\n",
    "le_Y = LabelEncoder()\n",
    "tags_Y = le_Y.fit_transform(tags_Y.astype(str))\n",
    "tok_Y = Tokenizer(num_words=num_max)\n",
    "tok_Y.fit_on_texts(texts_Y)\n",
    "mat_texts_Y = tok.texts_to_matrix(texts_Y,mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "\n",
    "# For testing data\n",
    "cnn_texts_seq_Y = tok.texts_to_sequences(texts_Y)\n",
    "cnn_texts_mat_Y = sequence.pad_sequences(cnn_texts_seq_Y,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"text_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=4, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    # load the whole embedding into memory\n",
    "    embeddings_index = dict()\n",
    "    f = open('Embeddings/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = np.zeros((len(tok.word_index) + 1, 100))\n",
    "    for word, i in tok.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    #text classifier\n",
    "    inputs = Input(shape=(100,))\n",
    "    e = Embedding(len(tok.word_index) + 1,\n",
    "                  100, \n",
    "                  weights=[embedding_matrix],\n",
    "                  input_length=max_len, \n",
    "                  trainable=False)(inputs)\n",
    "    x = Dropout(0.2)(e)\n",
    "    x = Conv1D(128,\n",
    "               3,\n",
    "               padding='valid',\n",
    "               activation='relu',\n",
    "               strides=1)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    hybrid_link = Dense(32, activation='relu', name='hybrid_link')(x)\n",
    "    x = Dense(1, activation='sigmoid', name='Text_Classifier')(hybrid_link)\n",
    "    text_classifier = x\n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(4, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    #hybrid model\n",
    "    concatenate_layer = concatenate([image_model, hybrid_link]) \n",
    "    hybrid = Dense(4, activation='softmax', name='Hybrid_Classifier')(concatenate_layer)\n",
    "    model = Model(inputs=[vgg.input, inputs], outputs=[hybrid,text_classifier])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(4, activation = 'softmax',name='Hybrid_Classifier')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    model = Model(inputs=[vgg.input], outputs=[image_model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "hybrid_model = get_hybrid_model()\n",
    "vgg_model = get_vgg_model()\n",
    "\n",
    "hybrid_model.compile(loss=['categorical_crossentropy','binary_crossentropy'],\n",
    "                       optimizer= optimizers.Nadam(lr=0.00075,\n",
    "                                                   beta_1=0.5,\n",
    "                                                   beta_2=0.999,\n",
    "                                                   epsilon=None, \n",
    "                                                   schedule_decay=0.0001),\n",
    "                       metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])\n",
    "# .8039\n",
    "# hybrid_model.compile(loss=['categorical_crossentropy','binary_crossentropy'],\n",
    "#                        optimizer= optimizers.Nadam(lr=0.0006,\n",
    "#                                                    beta_1=0.9,\n",
    "#                                                    beta_2=0.999,\n",
    "#                                                    epsilon=None, \n",
    "#                                                    schedule_decay=0.0004),\n",
    "#                        metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])\n",
    "plot_model(hybrid_model, to_file='hybrid.png')\n",
    "plot_model(vgg_model, to_file='vgg.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE =224\n",
    "dataset_dir = 'H:/FYP DATASETS/FYP DATASETS/Crisis/'\n",
    "\n",
    "def load_img(img):\n",
    "    path = os.path.join(dataset_dir, img)\n",
    "    rows=224\n",
    "    columns=224\n",
    "    img= cv2.resize(cv2.imread(path,cv2.IMREAD_COLOR),(rows,columns),interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    train.at[index,'image_path'] = load_img(row['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(damage):\n",
    "    # integer encode\n",
    "    damage = np.array(damage)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(damage)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\conda\\conda\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          HARVEY AFTER DONNA KISSED HIM: https://t.co/mz...\n",
      "text_info                                       not_informative\n",
      "image_path    [[[141, 150, 137], [141, 150, 137], [141, 150,...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = encode_label(train.iloc[:]['damage'])\n",
    "print(train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['irrelevant' 'severe_damage' 'mild_damage' 'little_or_no_damage']\n"
     ]
    }
   ],
   "source": [
    "print(train.damage.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train['image_path'].tolist()\n",
    "# no need to convert y to list as it is 1 dim encoding takes care of it\n",
    "train_images = np.array(train_images)\n",
    "train_text = np.array(train['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"hybrid_checkpoints_1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_Hybrid_Classifier_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_Hybrid_Classifier_acc', min_delta=0, patience=6, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "load_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10807 samples, validate on 3603 samples\n",
      "Epoch 1/60\n",
      "10807/10807 [==============================] - 438s 41ms/step - loss: 1.1538 - Hybrid_Classifier_loss: 0.6715 - Text_Classifier_loss: 0.4823 - Hybrid_Classifier_acc: 0.8048 - Hybrid_Classifier_mean_absolute_error: 0.1662 - Hybrid_Classifier_categorical_accuracy: 0.8048 - Text_Classifier_acc: 0.7776 - Text_Classifier_mean_absolute_error: 0.3103 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0752 - val_Hybrid_Classifier_loss: 0.6247 - val_Text_Classifier_loss: 0.4505 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1588 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.7985 - val_Text_Classifier_mean_absolute_error: 0.2661 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00001: val_Hybrid_Classifier_acc improved from -inf to 0.79961, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 2/60\n",
      "10807/10807 [==============================] - 400s 37ms/step - loss: 1.0560 - Hybrid_Classifier_loss: 0.6252 - Text_Classifier_loss: 0.4307 - Hybrid_Classifier_acc: 0.8062 - Hybrid_Classifier_mean_absolute_error: 0.1582 - Hybrid_Classifier_categorical_accuracy: 0.8062 - Text_Classifier_acc: 0.8081 - Text_Classifier_mean_absolute_error: 0.2741 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0434 - val_Hybrid_Classifier_loss: 0.6150 - val_Text_Classifier_loss: 0.4284 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1700 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.8177 - val_Text_Classifier_mean_absolute_error: 0.2991 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00002: val_Hybrid_Classifier_acc did not improve from 0.79961\n",
      "Epoch 3/60\n",
      "10807/10807 [==============================] - 395s 37ms/step - loss: 1.0167 - Hybrid_Classifier_loss: 0.6060 - Text_Classifier_loss: 0.4108 - Hybrid_Classifier_acc: 0.8061 - Hybrid_Classifier_mean_absolute_error: 0.1548 - Hybrid_Classifier_categorical_accuracy: 0.8061 - Text_Classifier_acc: 0.8204 - Text_Classifier_mean_absolute_error: 0.2607 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0276 - val_Hybrid_Classifier_loss: 0.6087 - val_Text_Classifier_loss: 0.4189 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1425 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.8154 - val_Text_Classifier_mean_absolute_error: 0.2588 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: val_Hybrid_Classifier_acc did not improve from 0.79961\n",
      "Epoch 4/60\n",
      "10807/10807 [==============================] - 396s 37ms/step - loss: 0.9913 - Hybrid_Classifier_loss: 0.5908 - Text_Classifier_loss: 0.4005 - Hybrid_Classifier_acc: 0.8057 - Hybrid_Classifier_mean_absolute_error: 0.1517 - Hybrid_Classifier_categorical_accuracy: 0.8057 - Text_Classifier_acc: 0.8233 - Text_Classifier_mean_absolute_error: 0.2536 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0137 - val_Hybrid_Classifier_loss: 0.6100 - val_Text_Classifier_loss: 0.4037 - val_Hybrid_Classifier_acc: 0.7993 - val_Hybrid_Classifier_mean_absolute_error: 0.1717 - val_Hybrid_Classifier_categorical_accuracy: 0.7993 - val_Text_Classifier_acc: 0.8226 - val_Text_Classifier_mean_absolute_error: 0.2523 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_Hybrid_Classifier_acc did not improve from 0.79961\n",
      "Epoch 5/60\n",
      "10807/10807 [==============================] - 397s 37ms/step - loss: 0.9637 - Hybrid_Classifier_loss: 0.5770 - Text_Classifier_loss: 0.3867 - Hybrid_Classifier_acc: 0.8069 - Hybrid_Classifier_mean_absolute_error: 0.1492 - Hybrid_Classifier_categorical_accuracy: 0.8069 - Text_Classifier_acc: 0.8272 - Text_Classifier_mean_absolute_error: 0.2442 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0015 - val_Hybrid_Classifier_loss: 0.5962 - val_Text_Classifier_loss: 0.4053 - val_Hybrid_Classifier_acc: 0.7996 - val_Hybrid_Classifier_mean_absolute_error: 0.1532 - val_Hybrid_Classifier_categorical_accuracy: 0.7996 - val_Text_Classifier_acc: 0.8235 - val_Text_Classifier_mean_absolute_error: 0.2626 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: val_Hybrid_Classifier_acc improved from 0.79961 to 0.79961, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 6/60\n",
      "10807/10807 [==============================] - 397s 37ms/step - loss: 0.9419 - Hybrid_Classifier_loss: 0.5651 - Text_Classifier_loss: 0.3767 - Hybrid_Classifier_acc: 0.8065 - Hybrid_Classifier_mean_absolute_error: 0.1463 - Hybrid_Classifier_categorical_accuracy: 0.8065 - Text_Classifier_acc: 0.8346 - Text_Classifier_mean_absolute_error: 0.2379 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0220 - val_Hybrid_Classifier_loss: 0.6082 - val_Text_Classifier_loss: 0.4137 - val_Hybrid_Classifier_acc: 0.7999 - val_Hybrid_Classifier_mean_absolute_error: 0.1680 - val_Hybrid_Classifier_categorical_accuracy: 0.7999 - val_Text_Classifier_acc: 0.8157 - val_Text_Classifier_mean_absolute_error: 0.2529 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00006: val_Hybrid_Classifier_acc improved from 0.79961 to 0.79989, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 7/60\n",
      "10807/10807 [==============================] - 399s 37ms/step - loss: 0.9190 - Hybrid_Classifier_loss: 0.5552 - Text_Classifier_loss: 0.3638 - Hybrid_Classifier_acc: 0.8087 - Hybrid_Classifier_mean_absolute_error: 0.1443 - Hybrid_Classifier_categorical_accuracy: 0.8087 - Text_Classifier_acc: 0.8400 - Text_Classifier_mean_absolute_error: 0.2280 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0104 - val_Hybrid_Classifier_loss: 0.6065 - val_Text_Classifier_loss: 0.4039 - val_Hybrid_Classifier_acc: 0.8029 - val_Hybrid_Classifier_mean_absolute_error: 0.1675 - val_Hybrid_Classifier_categorical_accuracy: 0.8029 - val_Text_Classifier_acc: 0.8301 - val_Text_Classifier_mean_absolute_error: 0.2579 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: val_Hybrid_Classifier_acc improved from 0.79989 to 0.80294, saving model to hybrid_checkpoints_1.h5\n",
      "Epoch 8/60\n",
      "10807/10807 [==============================] - 399s 37ms/step - loss: 0.8955 - Hybrid_Classifier_loss: 0.5425 - Text_Classifier_loss: 0.3530 - Hybrid_Classifier_acc: 0.8092 - Hybrid_Classifier_mean_absolute_error: 0.1413 - Hybrid_Classifier_categorical_accuracy: 0.8092 - Text_Classifier_acc: 0.8462 - Text_Classifier_mean_absolute_error: 0.2222 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0083 - val_Hybrid_Classifier_loss: 0.6034 - val_Text_Classifier_loss: 0.4049 - val_Hybrid_Classifier_acc: 0.8013 - val_Hybrid_Classifier_mean_absolute_error: 0.1510 - val_Hybrid_Classifier_categorical_accuracy: 0.8013 - val_Text_Classifier_acc: 0.8279 - val_Text_Classifier_mean_absolute_error: 0.2535 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00008: val_Hybrid_Classifier_acc did not improve from 0.80294\n",
      "Epoch 9/60\n",
      "10807/10807 [==============================] - 398s 37ms/step - loss: 0.8779 - Hybrid_Classifier_loss: 0.5332 - Text_Classifier_loss: 0.3447 - Hybrid_Classifier_acc: 0.8104 - Hybrid_Classifier_mean_absolute_error: 0.1399 - Hybrid_Classifier_categorical_accuracy: 0.8104 - Text_Classifier_acc: 0.8496 - Text_Classifier_mean_absolute_error: 0.2156 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0033 - val_Hybrid_Classifier_loss: 0.5989 - val_Text_Classifier_loss: 0.4044 - val_Hybrid_Classifier_acc: 0.8004 - val_Hybrid_Classifier_mean_absolute_error: 0.1494 - val_Hybrid_Classifier_categorical_accuracy: 0.8004 - val_Text_Classifier_acc: 0.8285 - val_Text_Classifier_mean_absolute_error: 0.2573 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00009: val_Hybrid_Classifier_acc did not improve from 0.80294\n",
      "Epoch 10/60\n",
      "10807/10807 [==============================] - 398s 37ms/step - loss: 0.8593 - Hybrid_Classifier_loss: 0.5233 - Text_Classifier_loss: 0.3360 - Hybrid_Classifier_acc: 0.8108 - Hybrid_Classifier_mean_absolute_error: 0.1375 - Hybrid_Classifier_categorical_accuracy: 0.8108 - Text_Classifier_acc: 0.8548 - Text_Classifier_mean_absolute_error: 0.2106 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0176 - val_Hybrid_Classifier_loss: 0.6047 - val_Text_Classifier_loss: 0.4128 - val_Hybrid_Classifier_acc: 0.8016 - val_Hybrid_Classifier_mean_absolute_error: 0.1638 - val_Hybrid_Classifier_categorical_accuracy: 0.8016 - val_Text_Classifier_acc: 0.8263 - val_Text_Classifier_mean_absolute_error: 0.2305 - val_Text_Classifier_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_Hybrid_Classifier_acc did not improve from 0.80294\n",
      "Epoch 11/60\n",
      "10807/10807 [==============================] - 394s 36ms/step - loss: 0.8332 - Hybrid_Classifier_loss: 0.5101 - Text_Classifier_loss: 0.3230 - Hybrid_Classifier_acc: 0.8143 - Hybrid_Classifier_mean_absolute_error: 0.1346 - Hybrid_Classifier_categorical_accuracy: 0.8143 - Text_Classifier_acc: 0.8599 - Text_Classifier_mean_absolute_error: 0.2013 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0264 - val_Hybrid_Classifier_loss: 0.6121 - val_Text_Classifier_loss: 0.4144 - val_Hybrid_Classifier_acc: 0.8010 - val_Hybrid_Classifier_mean_absolute_error: 0.1394 - val_Hybrid_Classifier_categorical_accuracy: 0.8010 - val_Text_Classifier_acc: 0.8140 - val_Text_Classifier_mean_absolute_error: 0.2519 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00011: val_Hybrid_Classifier_acc did not improve from 0.80294\n",
      "Epoch 12/60\n",
      "10807/10807 [==============================] - 394s 36ms/step - loss: 0.8197 - Hybrid_Classifier_loss: 0.5013 - Text_Classifier_loss: 0.3184 - Hybrid_Classifier_acc: 0.8133 - Hybrid_Classifier_mean_absolute_error: 0.1330 - Hybrid_Classifier_categorical_accuracy: 0.8133 - Text_Classifier_acc: 0.8630 - Text_Classifier_mean_absolute_error: 0.1989 - Text_Classifier_categorical_accuracy: 1.0000 - val_loss: 1.0428 - val_Hybrid_Classifier_loss: 0.6270 - val_Text_Classifier_loss: 0.4157 - val_Hybrid_Classifier_acc: 0.7991 - val_Hybrid_Classifier_mean_absolute_error: 0.1729 - val_Hybrid_Classifier_categorical_accuracy: 0.7991 - val_Text_Classifier_acc: 0.8257 - val_Text_Classifier_mean_absolute_error: 0.2309 - val_Text_Classifier_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00012: val_Hybrid_Classifier_acc did not improve from 0.80294\n",
      "Epoch 13/60\n",
      "10800/10807 [============================>.] - ETA: 0s - loss: 0.8087 - Hybrid_Classifier_loss: 0.4964 - Text_Classifier_loss: 0.3123 - Hybrid_Classifier_acc: 0.8173 - Hybrid_Classifier_mean_absolute_error: 0.1324 - Hybrid_Classifier_categorical_accuracy: 0.8173 - Text_Classifier_acc: 0.8636 - Text_Classifier_mean_absolute_error: 0.1958 - Text_Classifier_categorical_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hybrid_model.save_weights('initial_hybrid.h5')\n",
    "hybrid_history = hybrid_model.fit(x=[train_images,cnn_texts_mat], y=[y,tags],\n",
    "                           epochs=60,\n",
    "                           batch_size=10,\n",
    "                           validation_split=0.25,\n",
    "                           shuffle=True,\n",
    "                           callbacks = callbacks_list,\n",
    "                           verbose=1)\n",
    "hybrid_time = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# vgg_history = vgg_model.fit(x=[train_images], y=[y],\n",
    "#                            epochs=40,\n",
    "#                            batch_size=10,\n",
    "#                            validation_split=0.2,\n",
    "#                            shuffle=True,\n",
    "#                            verbose=1)\n",
    "# vgg_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hybrid train time ' + str(hybrid_time))\n",
    "print('load time ' + str(load_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.save_weights('hybrid.h5')\n",
    "#vgg_model.save_weights('vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('shutdown /h')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
