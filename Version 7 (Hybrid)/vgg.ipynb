{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras import metrics\n",
    "from keras.layers.merge import concatenate\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utilities.model_visualization import model_to_png\n",
    "\n",
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os # used for navigating to image path\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "import cv2\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pickle\n",
    "from scipy import misc\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          HARVEY AFTER DONNA KISSED HIM: https://t.co/mz...\n",
      "text_info                                       not_informative\n",
      "image_path    data_image/hurricane_harvey/14_9_2017/90825435...\n",
      "damage                                               irrelevant\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_pickle('dataset.pkl')\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pos = int(df['text'].count()*0.8)\n",
    "train = df[:split_pos]\n",
    "test = df[split_pos:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_model():    # Pre Trained Embeddings\n",
    "    \n",
    "    #image classifier\n",
    "    IMAGE_SIZE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "    vgg = VGG16(input_shape = (224, 224, 3), weights = None, include_top = True)  # input_shape = (64,64,3) as required by VGG\n",
    "    x = (vgg.layers[-2].output)\n",
    "    image_model = Dense(4, activation = 'softmax',name='Hybrid_Classifier')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "    model = Model(inputs=[vgg.input], outputs=[image_model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"text_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=4, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = get_vgg_model()\n",
    "vgg_model.compile(loss=['categorical_crossentropy'],\n",
    "                       optimizer= optimizers.Nadam(lr=0.00075,\n",
    "                                                   beta_1=0.5,\n",
    "                                                   beta_2=0.999,\n",
    "                                                   epsilon=None, \n",
    "                                                   schedule_decay=0.0001),\n",
    "                       metrics=['accuracy',metrics.mae, metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE =224\n",
    "dataset_dir = 'H:/FYP DATASETS/FYP DATASETS/Crisis/'\n",
    "\n",
    "def load_img(img):\n",
    "    path = os.path.join(dataset_dir, img)\n",
    "    rows=224\n",
    "    columns=224\n",
    "    img= cv2.resize(cv2.imread(path,cv2.IMREAD_COLOR),(rows,columns),interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    train.at[index,'image_path'] = load_img(row['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(damage):\n",
    "    # integer encode\n",
    "    damage = np.array(damage)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(damage)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encode_label(train.iloc[:]['damage'])\n",
    "print(train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.damage.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train['image_path'].tolist()\n",
    "# no need to convert y to list as it is 1 dim encoding takes care of it\n",
    "train_images = np.array(train_images)\n",
    "train_text = np.array(train['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"divided_checkpoints_1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_vgg_output_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_vgg_output_acc', min_delta=0, patience=6, verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "load_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "vgg_history = vgg_model.fit(x=[train_images], y=[y],\n",
    "                           epochs=60,\n",
    "                           batch_size=10,\n",
    "                           validation_split=0.25,\n",
    "                           shuffle=True,\n",
    "                           callbacks = callbacks_list,\n",
    "                           verbose=1)\n",
    "vgg_time = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# vgg_history = vgg_model.fit(x=[train_images], y=[y],\n",
    "#                            epochs=40,\n",
    "#                            batch_size=10,\n",
    "#                            validation_split=0.2,\n",
    "#                            shuffle=True,\n",
    "#                            verbose=1)\n",
    "# vgg_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('vgg train time ' + str(vgg_time))\n",
    "print('load time ' + str(load_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.save_weights('vgg.h5')\n",
    "#vgg_model.save_weights('vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
