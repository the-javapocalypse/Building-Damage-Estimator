{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Description\n",
    "This script will use the pretrained VGG 16, Inception, Resnet, Mobilenet for classification. Here we will lookout for features that were common in images of earthquake and based on collective probabilities of top 5 features we will decide if the image is useful for us, i.e it is relevant or irrelevant (Eg. Meme) and will move the usfull images to __filtered__ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javapocalypse\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 415s 1us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 76s 1us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 64s 1us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
      "17227776/17225924 [==============================] - 21s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
    " \n",
    "#Load the VGG model\n",
    "vgg_model = vgg16.VGG16(weights='imagenet')\n",
    " \n",
    "#Load the Inception_V3 model\n",
    "inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
    " \n",
    "#Load the ResNet50 model\n",
    "resnet_model = resnet50.ResNet50(weights='imagenet')\n",
    " \n",
    "#Load the MobileNet model\n",
    "mobilenet_model = mobilenet.MobileNet(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processImage(base_dir,img_url):\n",
    "    filename = base_dir+img_url\n",
    "    # load an image in PIL format\n",
    "    original = load_img(filename, target_size=(224, 224))\n",
    "#     print('PIL image size',original.size)\n",
    "    plt.imshow(original)\n",
    "#     plt.show()\n",
    "\n",
    "    # convert the PIL image to a numpy array\n",
    "    # IN PIL - image is in (width, height, channel)\n",
    "    # In Numpy - image is in (height, width, channel)\n",
    "    numpy_image = img_to_array(original)\n",
    "#     plt.imshow(np.uint8(numpy_image))\n",
    "#     plt.show()\n",
    "#     print('numpy array size',numpy_image.shape)\n",
    "\n",
    "    # Convert the image / images into batch format\n",
    "    # expand_dims will add an extra dimension to the data at a particular axis\n",
    "    # We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "    # Thus we add the extra dimension to the axis 0.\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "#     print('image batch size', image_batch.shape)\n",
    "#     plt.imshow(np.uint8(image_batch[0]))\n",
    "    \n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(base_dir, img_url, model_preprocess, model_obj, model_name):\n",
    "    image_batch = processImage(base_dir, img_url)\n",
    "\n",
    "    # prepare the image for the VGG model\n",
    "    processed_image = model_preprocess.preprocess_input(image_batch.copy())\n",
    "\n",
    "    # get the predicted probabilities for each class\n",
    "    predictions = model_obj.predict(processed_image)\n",
    "    # print predictions\n",
    "\n",
    "    # convert the probabilities to class labels\n",
    "    # We will get top 5 predictions which is the default\n",
    "    label = decode_predictions(predictions)\n",
    "\n",
    "#     print(\"\\n\")\n",
    "#     print(\"Predictions of: \"+model_name)\n",
    "#     print(\"=\"*20)\n",
    "#     for i in range (0,5):\n",
    "#         print(label[0][i][1]+\": \"+str(\"{0:.2f}\".format(label[0][i][2]*100))+\"%\")\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def getFilesInDir(sourceDir):\n",
    "    onlyfiles = [f for f in listdir(sourceDir) if isfile(join(sourceDir, f))]\n",
    "    return onlyfiles\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 files processed\n",
      "100 files processed\n",
      "150 files processed\n",
      "200 files processed\n",
      "250 files processed\n",
      "300 files processed\n",
      "350 files processed\n",
      "400 files processed\n",
      "450 files processed\n",
      "500 files processed\n",
      "550 files processed\n",
      "600 files processed\n",
      "650 files processed\n",
      "700 files processed\n",
      "750 files processed\n",
      "800 files processed\n",
      "850 files processed\n",
      "900 files processed\n",
      "950 files processed\n",
      "1000 files processed\n",
      "1050 files processed\n",
      "1100 files processed\n",
      "1150 files processed\n",
      "1200 files processed\n",
      "1250 files processed\n",
      "1300 files processed\n",
      "1350 files processed\n",
      "1400 files processed\n",
      "1450 files processed\n",
      "1500 files processed\n",
      "1550 files processed\n",
      "1600 files processed\n",
      "1650 files processed\n",
      "1700 files processed\n",
      "1750 files processed\n",
      "1800 files processed\n",
      "1850 files processed\n",
      "1900 files processed\n",
      "1950 files processed\n",
      "2000 files processed\n",
      "2050 files processed\n",
      "2100 files processed\n",
      "2150 files processed\n",
      "2200 files processed\n",
      "2250 files processed\n",
      "2300 files processed\n",
      "2350 files processed\n",
      "2400 files processed\n",
      "2450 files processed\n",
      "2500 files processed\n",
      "2550 files processed\n",
      "2600 files processed\n",
      "2650 files processed\n",
      "2700 files processed\n",
      "2750 files processed\n",
      "2800 files processed\n",
      "2850 files processed\n",
      "2900 files processed\n",
      "2950 files processed\n",
      "3000 files processed\n",
      "3050 files processed\n",
      "3100 files processed\n",
      "3150 files processed\n",
      "3200 files processed\n",
      "3250 files processed\n",
      "3300 files processed\n",
      "3350 files processed\n",
      "3400 files processed\n",
      "3450 files processed\n",
      "3500 files processed\n",
      "3550 files processed\n",
      "3600 files processed\n",
      "3650 files processed\n",
      "3700 files processed\n",
      "3750 files processed\n",
      "3800 files processed\n",
      "3850 files processed\n",
      "3900 files processed\n",
      "3950 files processed\n",
      "4000 files processed\n",
      "4050 files processed\n",
      "4100 files processed\n",
      "4150 files processed\n",
      "4200 files processed\n",
      "4250 files processed\n",
      "4300 files processed\n",
      "4350 files processed\n",
      "4400 files processed\n",
      "4450 files processed\n",
      "4500 files processed\n",
      "4550 files processed\n",
      "4600 files processed\n",
      "4650 files processed\n",
      "4700 files processed\n",
      "4750 files processed\n",
      "4800 files processed\n",
      "4850 files processed\n",
      "4900 files processed\n",
      "4950 files processed\n",
      "5000 files processed\n",
      "5050 files processed\n",
      "5100 files processed\n",
      "5150 files processed\n",
      "5200 files processed\n",
      "5250 files processed\n",
      "5300 files processed\n",
      "5350 files processed\n",
      "5400 files processed\n",
      "5450 files processed\n",
      "5500 files processed\n",
      "5550 files processed\n",
      "5600 files processed\n",
      "5650 files processed\n",
      "5700 files processed\n",
      "5750 files processed\n",
      "5800 files processed\n",
      "5850 files processed\n",
      "5900 files processed\n",
      "5950 files processed\n",
      "6000 files processed\n",
      "6050 files processed\n",
      "6100 files processed\n",
      "6150 files processed\n",
      "6200 files processed\n",
      "6250 files processed\n",
      "6300 files processed\n",
      "6350 files processed\n",
      "6400 files processed\n",
      "6450 files processed\n",
      "6500 files processed\n"
     ]
    }
   ],
   "source": [
    "sourceDir = 'SMERP-2018-Dataset/nepal-quake-2015-images'\n",
    "filterDir = \"SMERP-2018-Dataset/filtered/\"\n",
    "\n",
    "onlyfiles = getFilesInDir(sourceDir)\n",
    "\n",
    "labels = ['knee_pad', 'stretcher', 'crash_helmet', 'cliff', 'ambulance', 'lakeside', 'half_track', 'garbage_truck', 'fire_engine', 'patio', 'plow', 'barrow', 'nail', 'hatchet', 'lumbermill', 'chain_saw', 'wood', 'military_uniform', 'rock', 'cobra', 'assault_rifle', 'syringe', 'mask', 'lifeboat', 'mountain', 'prison', 'swab', 'crutch', 'jinrikisha', 'hen-of-the-woods', 'tractor', 'snake', 'dwelling', 'church', 'monastery', 'band_aid', 'bath_towel', 'airliner', 'aircraft_carrier', 'shovel']\n",
    "counter = 0\n",
    "try:\n",
    "    for img in onlyfiles:\n",
    "        counter+=1\n",
    "        try:\n",
    "            vgg = predict(sourceDir, img, vgg16, vgg_model, \"VGG\")\n",
    "            inc = predict(sourceDir, img, inception_v3, inception_model, \"Inception\")\n",
    "            rnet = predict(sourceDir, img, resnet50, resnet_model, \"Resnet\")\n",
    "            mnet = predict(sourceDir, img, mobilenet, mobilenet_model, \"Mobilenet\")\n",
    "\n",
    "            if(counter%50==0):\n",
    "                print(str(counter)+\" files processed\")\n",
    "\n",
    "            # Move images to filtered folder\n",
    "            for i in range (0,5):\n",
    "                if vgg[0][i][1].lower() in labels or inc[0][i][1].lower() in labels or rnet[0][i][1].lower() in labels or mnet[0][i][1].lower() in labels:\n",
    "                    os.rename(sourceDir+\"/\"+img, filterDir+img)\n",
    "\n",
    "        except:\n",
    "#             print(\"Skipped: \"+str(img))\n",
    "            pass\n",
    "            \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
