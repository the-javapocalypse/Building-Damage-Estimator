{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javapocalypse\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "from sklearn.utils import shuffle\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = \"Dataset1/queensland/train.xlsx\"\n",
    "dataset_test = \"Dataset1/queensland/test.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tweet_id                                               text  \\\n",
      "676   295401764763611008  ARAI MOTOR BIKE HELMETBLACK ALMOST BRAND NEW 2...   \n",
      "1699  296087615508185024  EVERYONE STOP WHAT YOURE DOING LIKE s new FB P...   \n",
      "2144  297248827335905024      The lake university at Southbank Brisbane pic   \n",
      "5957  295757652447875008  Tony Abbott visiting flood affected areas Quee...   \n",
      "2880  295782312292006976                    Flood worsens eastern Australia   \n",
      "\n",
      "             label  \n",
      "676   not_relevant  \n",
      "1699  not_relevant  \n",
      "2144  not_relevant  \n",
      "5957      relevant  \n",
      "2880      relevant  \n",
      "------------------------------\n",
      "relevant        3248\n",
      "not_relevant    2771\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_excel(dataset_train)\n",
    "test = pd.read_excel(dataset_test)\n",
    "\n",
    "train = train.sample(frac=1)\n",
    "\n",
    "print(train.head())\n",
    "print('-'*30)\n",
    "print(train['label'].value_counts())\n",
    "print('-'*30)\n",
    "\n",
    "# train = train[train['text'].str.len()  15]\n",
    "\n",
    "# print('x'*50)\n",
    "# # df[df['column name'].map(len) < 2]\n",
    "# print(train.head())\n",
    "# print('-'*30)\n",
    "# print(train['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['text'][0]\n",
    "# train['label'][0]\n",
    "dataColumn = 'text'\n",
    "labelColumn = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = train[labelColumn]\n",
    "texts = train[dataColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "(6019,) (6019, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags.astype(str))\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[947, 9, 14]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 947   9  14]\n",
      "(6019, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simple_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.summary()\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['acc',metrics.binary_accuracy])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(num_max,)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    print('compile done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 513,025\n",
      "Trainable params: 513,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "Train on 4815 samples, validate on 1204 samples\n",
      "Epoch 1/10\n",
      "4815/4815 [==============================] - 1s 221us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 2/10\n",
      "4815/4815 [==============================] - 1s 168us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 3/10\n",
      "4815/4815 [==============================] - 1s 197us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 4/10\n",
      "4815/4815 [==============================] - 1s 217us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 5/10\n",
      "4815/4815 [==============================] - 1s 243us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 6/10\n",
      "4815/4815 [==============================] - 1s 161us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 7/10\n",
      "4815/4815 [==============================] - 1s 216us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 8/10\n",
      "4815/4815 [==============================] - 1s 201us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 9/10\n",
      "4815/4815 [==============================] - 1s 192us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n",
      "Epoch 10/10\n",
      "4815/4815 [==============================] - 1s 230us/step - loss: 7.3702 - acc: 0.5377 - val_loss: 7.2164 - val_acc: 0.5473\n"
     ]
    }
   ],
   "source": [
    "m = get_simple_model()\n",
    "check_model(m,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v1():   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4815 samples, validate on 1204 samples\n",
      "Epoch 1/10\n",
      "4815/4815 [==============================] - 1s 262us/step - loss: 0.2982 - acc: 0.8650 - binary_accuracy: 0.8650 - val_loss: 0.1211 - val_acc: 0.9626 - val_binary_accuracy: 0.9626\n",
      "Epoch 2/10\n",
      "4815/4815 [==============================] - 1s 175us/step - loss: 0.1045 - acc: 0.9672 - binary_accuracy: 0.9672 - val_loss: 0.1120 - val_acc: 0.9585 - val_binary_accuracy: 0.9585\n",
      "Epoch 3/10\n",
      "4815/4815 [==============================] - 1s 165us/step - loss: 0.0832 - acc: 0.9738 - binary_accuracy: 0.9738 - val_loss: 0.1020 - val_acc: 0.9701 - val_binary_accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "4815/4815 [==============================] - 1s 160us/step - loss: 0.0687 - acc: 0.9801 - binary_accuracy: 0.9801 - val_loss: 0.1136 - val_acc: 0.9610 - val_binary_accuracy: 0.9610\n",
      "Epoch 5/10\n",
      "4815/4815 [==============================] - 1s 213us/step - loss: 0.0628 - acc: 0.9817 - binary_accuracy: 0.9817 - val_loss: 0.1171 - val_acc: 0.9659 - val_binary_accuracy: 0.9659\n",
      "Epoch 6/10\n",
      "4815/4815 [==============================] - 1s 191us/step - loss: 0.0534 - acc: 0.9871 - binary_accuracy: 0.9871 - val_loss: 0.1235 - val_acc: 0.9626 - val_binary_accuracy: 0.9626\n",
      "Epoch 7/10\n",
      "4815/4815 [==============================] - 1s 158us/step - loss: 0.0461 - acc: 0.9886 - binary_accuracy: 0.9886 - val_loss: 0.1337 - val_acc: 0.9593 - val_binary_accuracy: 0.9593\n",
      "Epoch 8/10\n",
      "4815/4815 [==============================] - 1s 159us/step - loss: 0.0426 - acc: 0.9896 - binary_accuracy: 0.9896 - val_loss: 0.1446 - val_acc: 0.9568 - val_binary_accuracy: 0.9568\n",
      "Epoch 9/10\n",
      "4815/4815 [==============================] - 1s 197us/step - loss: 0.0388 - acc: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.1767 - val_acc: 0.9493 - val_binary_accuracy: 0.9493\n",
      "Epoch 10/10\n",
      "4815/4815 [==============================] - 1s 179us/step - loss: 0.0348 - acc: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.1563 - val_acc: 0.9560 - val_binary_accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "m = get_cnn_model_v1()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v2(): # added embed   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561\n",
      "Trainable params: 76,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4815 samples, validate on 1204 samples\n",
      "Epoch 1/10\n",
      "4815/4815 [==============================] - 1s 286us/step - loss: 0.2802 - acc: 0.8775 - binary_accuracy: 0.8775 - val_loss: 0.1068 - val_acc: 0.9668 - val_binary_accuracy: 0.9668\n",
      "Epoch 2/10\n",
      "4815/4815 [==============================] - 1s 154us/step - loss: 0.0981 - acc: 0.9693 - binary_accuracy: 0.9693 - val_loss: 0.0980 - val_acc: 0.9693 - val_binary_accuracy: 0.9693\n",
      "Epoch 3/10\n",
      "4815/4815 [==============================] - 1s 162us/step - loss: 0.0733 - acc: 0.9792 - binary_accuracy: 0.9792 - val_loss: 0.1195 - val_acc: 0.9601 - val_binary_accuracy: 0.9601\n",
      "Epoch 4/10\n",
      "4815/4815 [==============================] - 1s 170us/step - loss: 0.0600 - acc: 0.9830 - binary_accuracy: 0.9830 - val_loss: 0.1096 - val_acc: 0.9693 - val_binary_accuracy: 0.9693\n",
      "Epoch 5/10\n",
      "4815/4815 [==============================] - 1s 162us/step - loss: 0.0474 - acc: 0.9880 - binary_accuracy: 0.9880 - val_loss: 0.1292 - val_acc: 0.9610 - val_binary_accuracy: 0.9610\n",
      "Epoch 6/10\n",
      "4815/4815 [==============================] - 1s 155us/step - loss: 0.0393 - acc: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.1295 - val_acc: 0.9635 - val_binary_accuracy: 0.9635\n",
      "Epoch 7/10\n",
      "4815/4815 [==============================] - 1s 160us/step - loss: 0.0316 - acc: 0.9921 - binary_accuracy: 0.9921 - val_loss: 0.1371 - val_acc: 0.9610 - val_binary_accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "4815/4815 [==============================] - 1s 169us/step - loss: 0.0235 - acc: 0.9946 - binary_accuracy: 0.9946 - val_loss: 0.1472 - val_acc: 0.9601 - val_binary_accuracy: 0.9601\n",
      "Epoch 9/10\n",
      "4815/4815 [==============================] - 1s 161us/step - loss: 0.0224 - acc: 0.9940 - binary_accuracy: 0.9940 - val_loss: 0.1600 - val_acc: 0.9568 - val_binary_accuracy: 0.9568\n",
      "Epoch 10/10\n",
      "4815/4815 [==============================] - 1s 162us/step - loss: 0.0181 - acc: 0.9950 - binary_accuracy: 0.9950 - val_loss: 0.1682 - val_acc: 0.9610 - val_binary_accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "m = get_cnn_model_v2()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
