{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javapocalypse\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import asarray\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utilities.model_visualization import model_to_png\n",
    "\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = \"Dataset1/queensland/train.xlsx\"\n",
    "dataset_test = \"Dataset1/queensland/test.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tweet_id                                               text  \\\n",
      "1963  297282655832121024                                Ill money months I    \n",
      "3981  296005918695500992  Flood crisis claims fourth victim A threeyearo...   \n",
      "5582  296003966221824000  Were still updating Bowls Queensland website i...   \n",
      "4893  296082334241913984         Deadly flood waters rise eastern Australia   \n",
      "628   296365043640041024  Hate say time long overdue but time long overd...   \n",
      "\n",
      "             label  \n",
      "1963  not_relevant  \n",
      "3981      relevant  \n",
      "5582      relevant  \n",
      "4893      relevant  \n",
      "628   not_relevant  \n",
      "------------------------------\n",
      "relevant        3248\n",
      "not_relevant    2771\n",
      "Name: label, dtype: int64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_excel(dataset_train)\n",
    "test = pd.read_excel(dataset_test)\n",
    "\n",
    "train = train.sample(frac=1)\n",
    "test = test.sample(frac=1)\n",
    "\n",
    "print(train.head())\n",
    "print('-'*30)\n",
    "print(train['label'].value_counts())\n",
    "print('-'*30)\n",
    "\n",
    "# train = train[train['text'].str.len()  15]\n",
    "\n",
    "# print('x'*50)\n",
    "# # df[df['column name'].map(len) < 2]\n",
    "# print(train.head())\n",
    "# print('-'*30)\n",
    "# print(train['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['text'][0]\n",
    "# train['label'][0]\n",
    "dataColumn = 'text'\n",
    "labelColumn = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = train[labelColumn]\n",
    "texts = train[dataColumn]\n",
    "\n",
    "tags_Y = test[labelColumn]\n",
    "texts_Y = test[dataColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(6019,) (6019, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags.astype(str))\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)\n",
    "\n",
    "\n",
    "# For testing data\n",
    "le_Y = LabelEncoder()\n",
    "tags_Y = le_Y.fit_transform(tags_Y.astype(str))\n",
    "tok_Y = Tokenizer(num_words=num_max)\n",
    "tok_Y.fit_on_texts(texts_Y)\n",
    "mat_texts_Y = tok.texts_to_matrix(texts_Y,mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208, 424, 517, 4]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 208 424 517   4]\n",
      "(6019, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)\n",
    "\n",
    "\n",
    "\n",
    "# For testing data\n",
    "cnn_texts_seq_Y = tok.texts_to_sequences(texts_Y)\n",
    "cnn_texts_mat_Y = sequence.pad_sequences(cnn_texts_seq_Y,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=12,verbose=1,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(num_max,)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    print('compile done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 513,025\n",
      "Trainable params: 513,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "Train on 4514 samples, validate on 1505 samples\n",
      "Epoch 1/12\n",
      "4514/4514 [==============================] - 1s 219us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 2/12\n",
      "4514/4514 [==============================] - 1s 174us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 3/12\n",
      "4514/4514 [==============================] - 1s 246us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 4/12\n",
      "4514/4514 [==============================] - 1s 194us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 5/12\n",
      "4514/4514 [==============================] - 1s 201us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 6/12\n",
      "4514/4514 [==============================] - 1s 225us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 7/12\n",
      "4514/4514 [==============================] - 1s 229us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 8/12\n",
      "4514/4514 [==============================] - 1s 219us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 9/12\n",
      "4514/4514 [==============================] - 1s 207us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 10/12\n",
      "4514/4514 [==============================] - 1s 222us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 11/12\n",
      "4514/4514 [==============================] - 1s 192us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n",
      "Epoch 12/12\n",
      "4514/4514 [==============================] - 1s 223us/step - loss: 7.2613 - acc: 0.5445 - val_loss: 7.5740 - val_acc: 0.5249\n"
     ]
    }
   ],
   "source": [
    "m1 = get_simple_model()\n",
    "model_to_png(m1, 'model_1')\n",
    "check_model(m1,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v1():   \n",
    "    model = Sequential()\n",
    "    # Starting off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Javapocalypse\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4514 samples, validate on 1505 samples\n",
      "Epoch 1/12\n",
      "4514/4514 [==============================] - 6s 1ms/step - loss: 0.3129 - acc: 0.8458 - binary_accuracy: 0.8458 - val_loss: 0.1316 - val_acc: 0.9615 - val_binary_accuracy: 0.9615\n",
      "Epoch 2/12\n",
      "4514/4514 [==============================] - 1s 219us/step - loss: 0.1070 - acc: 0.9668 - binary_accuracy: 0.9668 - val_loss: 0.1381 - val_acc: 0.9561 - val_binary_accuracy: 0.9561\n",
      "Epoch 3/12\n",
      "4514/4514 [==============================] - 1s 255us/step - loss: 0.0818 - acc: 0.9765 - binary_accuracy: 0.9765 - val_loss: 0.1348 - val_acc: 0.9608 - val_binary_accuracy: 0.9608\n",
      "Epoch 4/12\n",
      "4514/4514 [==============================] - 1s 227us/step - loss: 0.0735 - acc: 0.9792 - binary_accuracy: 0.9792 - val_loss: 0.1234 - val_acc: 0.9628 - val_binary_accuracy: 0.9628\n",
      "Epoch 5/12\n",
      "4514/4514 [==============================] - 1s 218us/step - loss: 0.0593 - acc: 0.9827 - binary_accuracy: 0.9827 - val_loss: 0.1247 - val_acc: 0.9608 - val_binary_accuracy: 0.9608\n",
      "Epoch 6/12\n",
      "4514/4514 [==============================] - 1s 232us/step - loss: 0.0523 - acc: 0.9847 - binary_accuracy: 0.9847 - val_loss: 0.1355 - val_acc: 0.9615 - val_binary_accuracy: 0.9615\n",
      "Epoch 7/12\n",
      "4514/4514 [==============================] - 1s 190us/step - loss: 0.0419 - acc: 0.9876 - binary_accuracy: 0.9876 - val_loss: 0.1507 - val_acc: 0.9568 - val_binary_accuracy: 0.9568\n",
      "Epoch 8/12\n",
      "4514/4514 [==============================] - 1s 193us/step - loss: 0.0435 - acc: 0.9874 - binary_accuracy: 0.9874 - val_loss: 0.1498 - val_acc: 0.9561 - val_binary_accuracy: 0.9561\n",
      "Epoch 9/12\n",
      "4514/4514 [==============================] - 1s 176us/step - loss: 0.0378 - acc: 0.9900 - binary_accuracy: 0.9900 - val_loss: 0.1597 - val_acc: 0.9575 - val_binary_accuracy: 0.9575\n",
      "Epoch 10/12\n",
      "4514/4514 [==============================] - 1s 193us/step - loss: 0.0304 - acc: 0.9918 - binary_accuracy: 0.9918 - val_loss: 0.1666 - val_acc: 0.9561 - val_binary_accuracy: 0.9561\n",
      "Epoch 11/12\n",
      "4514/4514 [==============================] - 1s 263us/step - loss: 0.0292 - acc: 0.9929 - binary_accuracy: 0.9929 - val_loss: 0.1716 - val_acc: 0.9555 - val_binary_accuracy: 0.9555\n",
      "Epoch 12/12\n",
      "4514/4514 [==============================] - 1s 184us/step - loss: 0.0265 - acc: 0.9927 - binary_accuracy: 0.9927 - val_loss: 0.1827 - val_acc: 0.9515 - val_binary_accuracy: 0.9515\n"
     ]
    }
   ],
   "source": [
    "m2 = get_cnn_model_v1()\n",
    "model_to_png(m2, 'model_2')\n",
    "check_model(m2,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v2():\n",
    "    model = Sequential()\n",
    "    # Increased Output Dim\n",
    "    model.add(Embedding(1000,\n",
    "                        50,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561\n",
      "Trainable params: 76,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4514 samples, validate on 1505 samples\n",
      "Epoch 1/12\n",
      "4514/4514 [==============================] - 1s 303us/step - loss: 0.2646 - acc: 0.8855 - binary_accuracy: 0.8855 - val_loss: 0.1310 - val_acc: 0.9548 - val_binary_accuracy: 0.9548\n",
      "Epoch 2/12\n",
      "4514/4514 [==============================] - 1s 167us/step - loss: 0.1031 - acc: 0.9703 - binary_accuracy: 0.9703 - val_loss: 0.1234 - val_acc: 0.9621 - val_binary_accuracy: 0.9621\n",
      "Epoch 3/12\n",
      "4514/4514 [==============================] - 1s 176us/step - loss: 0.0763 - acc: 0.9785 - binary_accuracy: 0.9785 - val_loss: 0.1251 - val_acc: 0.9575 - val_binary_accuracy: 0.9575\n",
      "Epoch 4/12\n",
      "4514/4514 [==============================] - 1s 168us/step - loss: 0.0595 - acc: 0.9838 - binary_accuracy: 0.9838 - val_loss: 0.1253 - val_acc: 0.9608 - val_binary_accuracy: 0.9608\n",
      "Epoch 5/12\n",
      "4514/4514 [==============================] - 1s 199us/step - loss: 0.0490 - acc: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.1560 - val_acc: 0.9508 - val_binary_accuracy: 0.9508\n",
      "Epoch 6/12\n",
      "4514/4514 [==============================] - 1s 239us/step - loss: 0.0415 - acc: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.1682 - val_acc: 0.9455 - val_binary_accuracy: 0.9455\n",
      "Epoch 7/12\n",
      "4514/4514 [==============================] - 1s 244us/step - loss: 0.0362 - acc: 0.9911 - binary_accuracy: 0.9911 - val_loss: 0.1605 - val_acc: 0.9542 - val_binary_accuracy: 0.9542\n",
      "Epoch 8/12\n",
      "4514/4514 [==============================] - 1s 234us/step - loss: 0.0305 - acc: 0.9925 - binary_accuracy: 0.9925 - val_loss: 0.1753 - val_acc: 0.9548 - val_binary_accuracy: 0.9548\n",
      "Epoch 9/12\n",
      "4514/4514 [==============================] - 1s 179us/step - loss: 0.0269 - acc: 0.9938 - binary_accuracy: 0.9938 - val_loss: 0.1889 - val_acc: 0.9495 - val_binary_accuracy: 0.9495\n",
      "Epoch 10/12\n",
      "4514/4514 [==============================] - 1s 181us/step - loss: 0.0248 - acc: 0.9931 - binary_accuracy: 0.9931 - val_loss: 0.1818 - val_acc: 0.9488 - val_binary_accuracy: 0.9488\n",
      "Epoch 11/12\n",
      "4514/4514 [==============================] - 1s 167us/step - loss: 0.0212 - acc: 0.9958 - binary_accuracy: 0.9958 - val_loss: 0.1928 - val_acc: 0.9528 - val_binary_accuracy: 0.9528\n",
      "Epoch 12/12\n",
      "4514/4514 [==============================] - 1s 244us/step - loss: 0.0185 - acc: 0.9953 - binary_accuracy: 0.9953 - val_loss: 0.2083 - val_acc: 0.9515 - val_binary_accuracy: 0.9515\n"
     ]
    }
   ],
   "source": [
    "m3 = get_cnn_model_v2()\n",
    "model_to_png(m3, 'model_3')\n",
    "check_model(m3,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v3():    # added filter\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(1000,\n",
    "                        50,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 256)           38656     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 121,681\n",
      "Trainable params: 121,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4514 samples, validate on 1505 samples\n",
      "Epoch 1/12\n",
      "4514/4514 [==============================] - 2s 377us/step - loss: 0.2534 - acc: 0.8930 - binary_accuracy: 0.8930 - val_loss: 0.1133 - val_acc: 0.9654 - val_binary_accuracy: 0.9654\n",
      "Epoch 2/12\n",
      "4514/4514 [==============================] - 1s 188us/step - loss: 0.0999 - acc: 0.9699 - binary_accuracy: 0.9699 - val_loss: 0.1111 - val_acc: 0.9661 - val_binary_accuracy: 0.9661\n",
      "Epoch 3/12\n",
      "4514/4514 [==============================] - 1s 236us/step - loss: 0.0763 - acc: 0.9794 - binary_accuracy: 0.9794 - val_loss: 0.1496 - val_acc: 0.9482 - val_binary_accuracy: 0.9482\n",
      "Epoch 4/12\n",
      "4514/4514 [==============================] - 1s 225us/step - loss: 0.0586 - acc: 0.9823 - binary_accuracy: 0.9823 - val_loss: 0.1475 - val_acc: 0.9508 - val_binary_accuracy: 0.9508\n",
      "Epoch 5/12\n",
      "4514/4514 [==============================] - 1s 217us/step - loss: 0.0501 - acc: 0.9883 - binary_accuracy: 0.9883 - val_loss: 0.1382 - val_acc: 0.9561 - val_binary_accuracy: 0.9561\n",
      "Epoch 6/12\n",
      "4514/4514 [==============================] - 1s 245us/step - loss: 0.0363 - acc: 0.9918 - binary_accuracy: 0.9918 - val_loss: 0.1678 - val_acc: 0.9502 - val_binary_accuracy: 0.9502\n",
      "Epoch 7/12\n",
      "4514/4514 [==============================] - 1s 183us/step - loss: 0.0297 - acc: 0.9931 - binary_accuracy: 0.9931 - val_loss: 0.1652 - val_acc: 0.9508 - val_binary_accuracy: 0.9508\n",
      "Epoch 8/12\n",
      "4514/4514 [==============================] - 1s 202us/step - loss: 0.0289 - acc: 0.9940 - binary_accuracy: 0.9940 - val_loss: 0.1807 - val_acc: 0.9495 - val_binary_accuracy: 0.9495\n",
      "Epoch 9/12\n",
      "4514/4514 [==============================] - 1s 262us/step - loss: 0.0271 - acc: 0.9927 - binary_accuracy: 0.9927 - val_loss: 0.1843 - val_acc: 0.9581 - val_binary_accuracy: 0.9581\n",
      "Epoch 10/12\n",
      "4514/4514 [==============================] - 1s 237us/step - loss: 0.0190 - acc: 0.9949 - binary_accuracy: 0.9949 - val_loss: 0.2054 - val_acc: 0.9575 - val_binary_accuracy: 0.9575\n",
      "Epoch 11/12\n",
      "4514/4514 [==============================] - 1s 226us/step - loss: 0.0160 - acc: 0.9958 - binary_accuracy: 0.9958 - val_loss: 0.2315 - val_acc: 0.9435 - val_binary_accuracy: 0.9435\n",
      "Epoch 12/12\n",
      "4514/4514 [==============================] - 1s 225us/step - loss: 0.0167 - acc: 0.9949 - binary_accuracy: 0.9949 - val_loss: 0.2193 - val_acc: 0.9515 - val_binary_accuracy: 0.9515\n"
     ]
    }
   ],
   "source": [
    "m4 = get_cnn_model_v3()\n",
    "model_to_png(m4, 'model_4')\n",
    "check_model(m4,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v4():    # Pre Trained Embeddings\n",
    "    \n",
    "    # load the whole embedding into memory\n",
    "    embeddings_index = dict()\n",
    "    f = open('Embeddings/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = np.zeros((len(tok.word_index) + 1, 100))\n",
    "    for word, i in tok.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    \n",
    "    model = Sequential()    \n",
    "    e = Embedding(len(tok.word_index) + 1, 100, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "    model.add(e)  #!!!!!!!!!!!!!!!!!!!\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, \n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          908400    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 128)           38528     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 967,601\n",
      "Trainable params: 59,201\n",
      "Non-trainable params: 908,400\n",
      "_________________________________________________________________\n",
      "Train on 4514 samples, validate on 1505 samples\n",
      "Epoch 1/12\n",
      "4514/4514 [==============================] - 1s 321us/step - loss: 0.1955 - acc: 0.9338 - binary_accuracy: 0.9338 - val_loss: 0.1486 - val_acc: 0.9548 - val_binary_accuracy: 0.9548\n",
      "Epoch 2/12\n",
      "4514/4514 [==============================] - 1s 162us/step - loss: 0.1207 - acc: 0.9590 - binary_accuracy: 0.9590 - val_loss: 0.1148 - val_acc: 0.9621 - val_binary_accuracy: 0.9621\n",
      "Epoch 3/12\n",
      "4514/4514 [==============================] - 1s 157us/step - loss: 0.1055 - acc: 0.9657 - binary_accuracy: 0.9657 - val_loss: 0.1071 - val_acc: 0.9641 - val_binary_accuracy: 0.9641\n",
      "Epoch 4/12\n",
      "4514/4514 [==============================] - 1s 167us/step - loss: 0.0894 - acc: 0.9725 - binary_accuracy: 0.9725 - val_loss: 0.1053 - val_acc: 0.9674 - val_binary_accuracy: 0.9674\n",
      "Epoch 5/12\n",
      "4514/4514 [==============================] - 1s 199us/step - loss: 0.0760 - acc: 0.9739 - binary_accuracy: 0.9739 - val_loss: 0.1118 - val_acc: 0.9648 - val_binary_accuracy: 0.9648\n",
      "Epoch 6/12\n",
      "4514/4514 [==============================] - 1s 193us/step - loss: 0.0662 - acc: 0.9772 - binary_accuracy: 0.9772 - val_loss: 0.1250 - val_acc: 0.9588 - val_binary_accuracy: 0.9588\n",
      "Epoch 7/12\n",
      "4514/4514 [==============================] - 1s 181us/step - loss: 0.0708 - acc: 0.9776 - binary_accuracy: 0.9776 - val_loss: 0.1064 - val_acc: 0.9648 - val_binary_accuracy: 0.9648\n",
      "Epoch 8/12\n",
      "4514/4514 [==============================] - 1s 220us/step - loss: 0.0469 - acc: 0.9840 - binary_accuracy: 0.9840 - val_loss: 0.1261 - val_acc: 0.9635 - val_binary_accuracy: 0.9635\n",
      "Epoch 9/12\n",
      "4514/4514 [==============================] - 1s 162us/step - loss: 0.0484 - acc: 0.9854 - binary_accuracy: 0.9854 - val_loss: 0.1322 - val_acc: 0.9641 - val_binary_accuracy: 0.9641\n",
      "Epoch 10/12\n",
      "4514/4514 [==============================] - 1s 164us/step - loss: 0.0436 - acc: 0.9865 - binary_accuracy: 0.9865 - val_loss: 0.1465 - val_acc: 0.9635 - val_binary_accuracy: 0.9635\n",
      "Epoch 11/12\n",
      "4514/4514 [==============================] - 1s 169us/step - loss: 0.0360 - acc: 0.9867 - binary_accuracy: 0.9867 - val_loss: 0.1395 - val_acc: 0.9608 - val_binary_accuracy: 0.9608\n",
      "Epoch 12/12\n",
      "4514/4514 [==============================] - 1s 192us/step - loss: 0.0371 - acc: 0.9872 - binary_accuracy: 0.9872 - val_loss: 0.1534 - val_acc: 0.9648 - val_binary_accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "m5 = get_cnn_model_v4()\n",
    "model_to_png(m5, 'model_5')\n",
    "check_model(m5,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 0s 58us/step\n",
      "53.97% Accurate ANN\n",
      "--------------------------------------------------\n",
      "3011/3011 [==============================] - 0s 53us/step\n",
      "93.92% Accurate CNN with Embedding\n",
      "--------------------------------------------------\n",
      "3011/3011 [==============================] - 0s 67us/step\n",
      "94.75% Accurate CNN with Embedding and more Filters\n",
      "--------------------------------------------------\n",
      "3011/3011 [==============================] - 0s 64us/step\n",
      "95.78% Accurate CNN with PRe Trained GLOVE Embedding\n"
     ]
    }
   ],
   "source": [
    "scores = m1.evaluate(mat_texts_Y, tags_Y)\n",
    "print('{0:.2f}'.format(scores[1]*100) + '% Accurate ANN')\n",
    "print('-'*50)\n",
    "scores = m3.evaluate(cnn_texts_mat_Y, tags_Y)\n",
    "print('{0:.2f}'.format(scores[1]*100) + '% Accurate CNN with Embedding')\n",
    "print('-'*50)\n",
    "scores = m4.evaluate(cnn_texts_mat_Y, tags_Y)\n",
    "print('{0:.2f}'.format(scores[1]*100) + '% Accurate CNN with Embedding and more Filters')\n",
    "print('-'*50)\n",
    "scores = m5.evaluate(cnn_texts_mat_Y, tags_Y)\n",
    "print('{0:.2f}'.format(scores[1]*100) + '% Accurate CNN with PRe Trained GLOVE Embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
